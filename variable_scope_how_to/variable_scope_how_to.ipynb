{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable Scope\n",
    "\n",
    "\n",
    "你可以如在 [Variables HowTo](https://www.tensorflow.org/versions/r0.10/how_tos/variable_scope/index.html)中所说的那样创建一个变量，并对其初始化，保存和加载。但是当你在构建一个非常复杂的模型的时候，你经常会需要共享很多的变量，并且你可能需要同时初始化所有的变量。这些都可以通过variable scope来实现。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable sharing\n",
    "\n",
    "假设我们要有一个函数能够对图像进行处理，我们的输入是两张图片，对这两张图片先分别调用图像处理函数，然后在对两张图片的处理结果进行合并。但是我们要注意到tensorflow的不同之处在于，其每一步操作都会被附加到graph上，调用一次函数，该函数内部的所有操作都会被附加到graph上，而多次调用这些操作就会被附加多次。\n",
    "\n",
    "\n",
    "我们可以考虑以下这个图像处理函数：\n",
    "\n",
    "```python\n",
    "def my_image_filter(input_images):\n",
    "    conv1_weights = tf.Variable(tf.random_normal([5, 5, 32, 32]),\n",
    "        name=\"conv1_weights\")\n",
    "    conv1_biases = tf.Variable(tf.zeros([32]), name=\"conv1_biases\")\n",
    "    conv1 = tf.nn.conv2d(input_images, conv1_weights,\n",
    "        strides=[1, 1, 1, 1], padding='SAME')\n",
    "    relu1 = tf.nn.relu(conv1 + conv1_biases)\n",
    "\n",
    "    conv2_weights = tf.Variable(tf.random_normal([5, 5, 32, 32]),\n",
    "        name=\"conv2_weights\")\n",
    "    conv2_biases = tf.Variable(tf.zeros([32]), name=\"conv2_biases\")\n",
    "    conv2 = tf.nn.conv2d(relu1, conv2_weights,\n",
    "        strides=[1, 1, 1, 1], padding='SAME')\n",
    "    return tf.nn.relu(conv2 + conv2_biases)\n",
    "```\n",
    "\n",
    "\n",
    "如果我们分别对image1和image2 调用一次图像处理函数，那么就会产生8个变量，\n",
    "```python\n",
    "# First call creates one set of 4 variables.\n",
    "result1 = my_image_filter(image1)\n",
    "# Another set of 4 variables is created in the second call.\n",
    "result2 = my_image_filter(image2)\n",
    "```\n",
    "\n",
    "但是我们想让这两个图像被同样的参数处理，我们可以将变量部分和操作部分分开：\n",
    "\n",
    "```python\n",
    "variables_dict = {\n",
    "    \"conv1_weights\": tf.Variable(tf.random_normal([5, 5, 32, 32]),\n",
    "        name=\"conv1_weights\")\n",
    "    \"conv1_biases\": tf.Variable(tf.zeros([32]), name=\"conv1_biases\")\n",
    "    ... etc. ...\n",
    "}\n",
    "\n",
    "def my_image_filter(input_images, variables_dict):\n",
    "    conv1 = tf.nn.conv2d(input_images, variables_dict[\"conv1_weights\"],\n",
    "        strides=[1, 1, 1, 1], padding='SAME')\n",
    "    relu1 = tf.nn.relu(conv1 + variables_dict[\"conv1_biases\"])\n",
    "\n",
    "    conv2 = tf.nn.conv2d(relu1, variables_dict[\"conv2_weights\"],\n",
    "        strides=[1, 1, 1, 1], padding='SAME')\n",
    "    return tf.nn.relu(conv2 + variables_dict[\"conv2_biases\"])\n",
    "\n",
    "# The 2 calls to my_image_filter() now use the same variables\n",
    "result1 = my_image_filter(image1, variables_dict)\n",
    "result2 = my_image_filter(image2, variables_dict)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable scope\n",
    "\n",
    "为了解决上述的变量共享的问题，tensorflow提供了variable scope。\n",
    "\n",
    "其主要是由两个函数组成：\n",
    "\n",
    "### * tf.get_variable(name, shape, initializer): Creates or returns a variable with a given name.\n",
    "\n",
    "### * tf.variable_scope(scope_name): Manages namespaces for names passed to tf.get_variable().\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 理解 tf.get_variable()\n",
    "\n",
    "我们通常这样来调用\n",
    "```python\n",
    "v = tf.get_variable(name, shape, dtype, initializer)\n",
    "```\n",
    "\n",
    "取决于该函数被调用时所在的variable scope，有两种不同的可能：\n",
    "\n",
    "1. 该scope被设定为创建新对象，此时 tf.get_variable_scope().reuse == False\n",
    "\n",
    "    在这种情况下，v会被创建为一个新对象，其shape和dtype由参数所决定。新创建的对象的名称被设定为 scope的name + 函数的参数name。\n",
    "    \n",
    "    并且tensorflow会做一个检查，确保这个新对象的名称之前不存在，否则这个函数会发生ValueError。\n",
    "    \n",
    "    ```python\n",
    "    with tf.variable_scope(\"foo\"):\n",
    "    v = tf.get_variable(\"v\", [1])\n",
    "    assert v.name == \"foo/v:0\"\n",
    "    ```\n",
    "2. 该scope被设定为reuse 变量，此时 tf.get_variable_scope().reuse == True\n",
    "    \n",
    "    在这种情况下，tensorflow会去搜索scope name + 函数的参数name组成的变量name是否存在，如果存在则返回该变量，如果不存在则抛出ValueError异常\n",
    "    \n",
    "    ```python\n",
    "    with tf.variable_scope(\"foo\"):\n",
    "    v = tf.get_variable(\"v\", [1])\n",
    "    with tf.variable_scope(\"foo\", reuse=True):\n",
    "    v1 = tf.get_variable(\"v\", [1])\n",
    "    assert v1 == v\n",
    "    ```\n",
    "   \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 理解tf.variable_scope()\n",
    "\n",
    "\n",
    "该函数可以接受一个name做为该scope的name，并且可以接受一个reuse-flag来决定是否reuse variable。同时，scope可以嵌套：\n",
    "\n",
    "```python\n",
    "with tf.variable_scope(\"foo\"):\n",
    "    with tf.variable_scope(\"bar\"):\n",
    "        v = tf.get_variable(\"v\", [1])\n",
    "assert v.name == \"foo/bar/v:0\"\n",
    "```\n",
    "\n",
    "\n",
    "#### 获取 当前scope & 将reuse flag 设置为True\n",
    "我们可以通过tf.get_variable_scope()函数来获取当前的variable scope，并且可以通过调用tf.get_variable_scope().reuse_variables():\n",
    "\n",
    " 函数来将该scope的reuse flag设置为True\n",
    " \n",
    "```python\n",
    "with tf.variable_scope(\"foo\"):\n",
    "    v = tf.get_variable(\"v\", [1])\n",
    "    tf.get_variable_scope().reuse_variables()\n",
    "    v1 = tf.get_variable(\"v\", [1])\n",
    "assert v1 == v\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### variable scope 的reuse设置成True之后不能设置为False\n",
    "\n",
    "注意你不能讲reuse flag设置成False。这样限定的目的是为了我们在创建模型时候能够将函数组合起来。假设一个人在一个reuse被设置成True的scope里面调用一个函数，他肯定期望这个函数里面的所有变量都是reuse的。如果我们能够将reuse设置成False，就会破坏这种一致性。\n",
    "\n",
    "虽然我们不可以显示地将reuse设置成显示地，但是我们可以进入一个reusing scope然后退出来。\n",
    "\n",
    "> 如果一个scope是reuse的，那么其subscope都是reuse的\n",
    "\n",
    "```python\n",
    "with tf.variable_scope(\"root\"):\n",
    "    # At start, the scope is not reusing.\n",
    "    assert tf.get_variable_scope().reuse == False\n",
    "    with tf.variable_scope(\"foo\"):\n",
    "        # Opened a sub-scope, still not reusing.\n",
    "        assert tf.get_variable_scope().reuse == False\n",
    "    with tf.variable_scope(\"foo\", reuse=True):\n",
    "        # Explicitly opened a reusing scope.\n",
    "        assert tf.get_variable_scope().reuse == True\n",
    "        with tf.variable_scope(\"bar\"):\n",
    "            # Now sub-scope inherits the reuse flag.\n",
    "            assert tf.get_variable_scope().reuse == True\n",
    "    # Exited the reusing scope, back to a non-reusing one.\n",
    "    assert tf.get_variable_scope().reuse == False\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### variable scope 的捕获\n",
    "\n",
    "\n",
    "在之前的例子中，我们都是用name这个参数来生成一个variable scope，但是如果我们能捕获这个scope就可以每次不通过name来获取这个scope\n",
    "\n",
    "\n",
    "```python\n",
    "with tf.variable_scope(\"foo\") as foo_scope:\n",
    "    v = tf.get_variable(\"v\", [1])\n",
    "with tf.variable_scope(foo_scope)\n",
    "    w = tf.get_variable(\"w\", [1])\n",
    "with tf.variable_scope(foo_scope, reuse=True)\n",
    "    v1 = tf.get_variable(\"v\", [1])\n",
    "    w1 = tf.get_variable(\"w\", [1])\n",
    "assert v1 == v\n",
    "assert w1 == w\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 重新打开一个被捕获scope的时候就会跳出当前的scope\n",
    "\n",
    "> 注意必须是被捕获的scope，并不是name参数获得的scope\n",
    "\n",
    "```python\n",
    "with tf.variable_scope(\"foo\") as foo_scope:\n",
    "    assert foo_scope.name == \"foo\"\n",
    "with tf.variable_scope(\"bar\")\n",
    "    with tf.variable_scope(\"baz\") as other_scope:\n",
    "        assert other_scope.name == \"bar/baz\"\n",
    "        with tf.variable_scope(foo_scope) as foo_scope2:\n",
    "            assert foo_scope2.name == \"foo\"  # Not changed.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bar/baz/foo\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-cecfa0e82fa2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"foo\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfoo_scope\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0;32mprint\u001b[0m \u001b[0mfoo_scope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0;32massert\u001b[0m \u001b[0mfoo_scope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"foo\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.variable_scope(\"foo\"):\n",
    "    assert tf.get_variable_scope().name ==\"foo\"\n",
    "with tf.variable_scope(\"bar\"):\n",
    "    with tf.variable_scope(\"baz\") as other_scope:\n",
    "        assert other_scope.name == \"bar/baz\"\n",
    "        with tf.variable_scope(\"foo\") as foo_scope:\n",
    "            print foo_scope.name\n",
    "            assert foo_scope.name == \"foo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"foo\") as foo_scope:\n",
    "    assert foo_scope.name == \"foo\"\n",
    "with tf.variable_scope(\"bar\"):\n",
    "    with tf.variable_scope(\"baz\") as other_scope:\n",
    "        assert other_scope.name == \"bar/baz\"\n",
    "        with tf.variable_scope(foo_scope) as foo_scope2:\n",
    "            assert foo_scope2.name == \"foo\"  # Not changed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### variable scope 的初始器(initializer)\n",
    "\n",
    "我们可以为一个scope指定initializer，这个scope里面的subscope也会继承这个initializer。但是为某个操作更明确地指定另一个initializer会覆盖默认的initializer\n",
    "\n",
    "```python\n",
    "with tf.variable_scope(\"foo\", initializer=tf.constant_initializer(0.4)):\n",
    "    v = tf.get_variable(\"v\", [1])\n",
    "    assert v.eval() == 0.4  # Default initializer as set above.\n",
    "    w = tf.get_variable(\"w\", [1], initializer=tf.constant_initializer(0.3)):\n",
    "    assert w.eval() == 0.3  # Specific initializer overrides the default.\n",
    "    with tf.variable_scope(\"bar\"):\n",
    "        v = tf.get_variable(\"v\", [1])\n",
    "        assert v.eval() == 0.4  # Inherited default initializer.\n",
    "    with tf.variable_scope(\"baz\", initializer=tf.constant_initializer(0.2)):\n",
    "        v = tf.get_variable(\"v\", [1])\n",
    "        assert v.eval() == 0.2  # Changed default initializer.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### variable scope对其中的operation的name的影响\n",
    "\n",
    "我们每次调用 with tf.variable_scope(\"name\")的时候，相当于默认执行了 tf.name_scope(\"name\"). \n",
    "\n",
    "```python\n",
    "with tf.variable_scope(\"foo\"):\n",
    "    x = 1.0 + tf.get_variable(\"v\", [1])\n",
    "assert x.op.name == \"foo/add\"\n",
    "```\n",
    "\n",
    "\n",
    "而且在一个variable scope 里面还可以open一个name scope\n",
    "\n",
    "```python\n",
    "with tf.variable_scope(\"foo\"):\n",
    "    with tf.name_scope(\"bar\"):\n",
    "        v = tf.get_variable(\"v\", [1])\n",
    "        x = 1.0 + v\n",
    "assert v.name == \"foo/v:0\"\n",
    "assert x.op.name == \"foo/bar/add\"\n",
    "```\n",
    "\n",
    "> 注意这里只有operation x 的name上加上了 name scope 而变量 v却没有,因为 v是由调用get_variable得到的, 这个函数会忽略name scope，只会对variable scope敏感。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "with tf.variable_scope(\"foo\"):\n",
    "    with tf.name_scope(\"bar\"):\n",
    "        y = tf.get_variable(\"y\", [1])\n",
    "        w = tf.Variable([[1.0]])\n",
    "        x = 1.0 + y\n",
    "\n",
    "print \"get_variable will ignore name_scope\"\n",
    "assert y.name == \"foo/y:0\"\n",
    "\n",
    "\n",
    "print w.name\n",
    "\n",
    "assert x.op.name == \"foo/bar/add\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### variable scope 和name scope\n",
    "\n",
    "variable scope对于variable 以及operation都有用，而name scope只是对operation有用。另外，get_variable会无视name scope\n",
    "\n",
    "\n",
    "```python\n",
    "with tf.Graph().as_default() as g:\n",
    "  c = tf.constant(5.0, name=\"c\")\n",
    "  assert c.op.name == \"c\"\n",
    "  c_1 = tf.constant(6.0, name=\"c\")\n",
    "  assert c_1.op.name == \"c_1\"\n",
    "\n",
    "  # Creates a scope called \"nested\"\n",
    "  with g.name_scope(\"nested\") as scope:\n",
    "    nested_c = tf.constant(10.0, name=\"c\")\n",
    "    assert nested_c.op.name == \"nested/c\"\n",
    "\n",
    "    # Creates a nested scope called \"inner\".\n",
    "    with g.name_scope(\"inner\"):\n",
    "      nested_inner_c = tf.constant(20.0, name=\"c\")\n",
    "      assert nested_inner_c.op.name == \"nested/inner/c\"\n",
    "\n",
    "    # Create a nested scope called \"inner_1\".\n",
    "    with g.name_scope(\"inner\"):\n",
    "      nested_inner_1_c = tf.constant(30.0, name=\"c\")\n",
    "      assert nested_inner_1_c.op.name == \"nested/inner_1/c\"\n",
    "\n",
    "      # Treats `scope` as an absolute name scope, and\n",
    "      # switches to the \"nested/\" scope.\n",
    "      with g.name_scope(scope):\n",
    "        nested_d = tf.constant(40.0, name=\"d\")\n",
    "        assert nested_d.op.name == \"nested/d\"\n",
    "\n",
    "        with g.name_scope(\"\"):\n",
    "          e = tf.constant(50.0, name=\"e\")\n",
    "          assert e.op.name == \"e\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
